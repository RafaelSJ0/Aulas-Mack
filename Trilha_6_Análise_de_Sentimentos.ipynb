{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "interpreter": {
      "hash": "54999d387da01ac009adc1c3ff01d1799bb96e6f581187d9006fa4c4da7ed267"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelSJ0/Aulas-Mack/blob/main/Trilha_6_An%C3%A1lise_de_Sentimentos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ2sbLzPFtR6"
      },
      "source": [
        "# Carregar as bibliotecas e dados"
      ],
      "id": "WQ2sbLzPFtR6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy3kwQPwFtSC"
      },
      "source": [
        "## Bibliotecas"
      ],
      "id": "jy3kwQPwFtSC"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaTt7lUTF8-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6a6fb7f-8025-482b-bcb0-30b99de9707c"
      },
      "source": [
        "!pip install unidecode\n",
        "!pip install fractions\n",
        "!pip install googletrans\n",
        "!pip install ibm_watson\n",
        "!pip install ibm_cloud_sdk_core\n",
        "!pip install dotenv\n"
      ],
      "id": "OaTt7lUTF8-n",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 22.2 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 24.9 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 61 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 71 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 81 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 92 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 112 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 122 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 143 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 153 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 163 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 174 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 184 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 194 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 204 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 215 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 225 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 19.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.4\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement fractions (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for fractions\u001b[0m\n",
            "Collecting googletrans\n",
            "  Downloading googletrans-3.0.0.tar.gz (17 kB)\n",
            "Collecting httpx==0.13.3\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (2021.10.8)\n",
            "Collecting rfc3986<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (2.10)\n",
            "Collecting hstspreload\n",
            "  Downloading hstspreload-2021.12.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 10.8 MB/s \n",
            "\u001b[?25hCollecting httpcore==0.9.*\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Collecting h11<0.10,>=0.8\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting h2==3.*\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.0.0-py3-none-any.whl size=15735 sha256=978290d00c2185a3fa6ee55c0fa3acd5bc7b2c0e81d10cb719a650936f5ad77d\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/da/eb/a54579056f265eede0417df537dd56d3df5b9eb2b25df0003d\n",
            "Successfully built googletrans\n",
            "Installing collected packages: hyperframe, hpack, sniffio, h2, h11, rfc3986, httpcore, hstspreload, httpx, googletrans\n",
            "Successfully installed googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2021.12.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 rfc3986-1.5.0 sniffio-1.2.0\n",
            "Collecting ibm_watson\n",
            "  Downloading ibm-watson-6.0.0.tar.gz (338 kB)\n",
            "\u001b[K     |████████████████████████████████| 338 kB 19.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting websocket-client==1.1.0\n",
            "  Downloading websocket_client-1.1.0-py2.py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from ibm_watson) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from ibm_watson) (2.8.2)\n",
            "Collecting ibm-cloud-sdk-core==3.*,>=3.3.6\n",
            "  Downloading ibm-cloud-sdk-core-3.15.1.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.1 MB/s \n",
            "\u001b[?25hCollecting requests<3.0,>=2.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting urllib3<2.0.0,>=1.26.0\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 60.8 MB/s \n",
            "\u001b[?25hCollecting PyJWT<3.0.0,>=2.0.1\n",
            "  Downloading PyJWT-2.3.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.5.3->ibm_watson) (1.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.0->ibm_watson) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.0->ibm_watson) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.0->ibm_watson) (2.0.12)\n",
            "Building wheels for collected packages: ibm-watson, ibm-cloud-sdk-core\n",
            "  Building wheel for ibm-watson (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-watson: filename=ibm_watson-6.0.0-py3-none-any.whl size=336807 sha256=5e3c094249805c46e7d375feb72512f6b852e8b13664f86e194184645d8a1d2a\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/de/dd/1002a4fdfeed1322ccffb20b0a12e00afbeeee8df4a86769d7\n",
            "  Building wheel for ibm-cloud-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cloud-sdk-core: filename=ibm_cloud_sdk_core-3.15.1-py3-none-any.whl size=83648 sha256=bbfa9f7b06cae66ecbd70636fc93843600bfcd00429b3cebd4c8140b07d00b36\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/7a/ac/408ba6a1438ea293164dbf26483b13a72165894a31e914b5e6\n",
            "Successfully built ibm-watson ibm-cloud-sdk-core\n",
            "Installing collected packages: urllib3, requests, PyJWT, websocket-client, ibm-cloud-sdk-core, ibm-watson\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed PyJWT-2.3.0 ibm-cloud-sdk-core-3.15.1 ibm-watson-6.0.0 requests-2.27.1 urllib3-1.26.9 websocket-client-1.1.0\n",
            "Requirement already satisfied: ibm_cloud_sdk_core in /usr/local/lib/python3.7/dist-packages (3.15.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.26.0 in /usr/local/lib/python3.7/dist-packages (from ibm_cloud_sdk_core) (2.27.1)\n",
            "Requirement already satisfied: PyJWT<3.0.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from ibm_cloud_sdk_core) (2.3.0)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.26.0 in /usr/local/lib/python3.7/dist-packages (from ibm_cloud_sdk_core) (1.26.9)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from ibm_cloud_sdk_core) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.5.3->ibm_cloud_sdk_core) (1.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.26.0->ibm_cloud_sdk_core) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.26.0->ibm_cloud_sdk_core) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.26.0->ibm_cloud_sdk_core) (2.0.12)\n",
            "Collecting dotenv\n",
            "  Downloading dotenv-0.0.5.tar.gz (2.4 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/e2/46/3754073706e31670eed18bfa8a879305b56a471db15f20523c2427b10078/dotenv-0.0.5.tar.gz#sha256=b58d2ab3f83dbd4f8a362b21158a606bee87317a9444485566b3c8f0af847091 (from https://pypi.org/simple/dotenv/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "  Downloading dotenv-0.0.4.tar.gz (2.0 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/2a/79/933746dc7f4891e5d7de0c113fd3c38cbf76bda0ea1b52df6484e3714928/dotenv-0.0.4.tar.gz#sha256=147fb269f4b65313079c4c2e2c9e74581f1e75c11c92555dcf5b5f48f24599a4 (from https://pypi.org/simple/dotenv/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "  Downloading dotenv-0.0.2.tar.gz (6.7 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/ca/41/d922e0b32beaf7251ff1540a4b5a13c54d6bc25ccd9704294524a1f3af17/dotenv-0.0.2.tar.gz#sha256=6a35c7afd2a1584ccfdcd2af22994b125846ded1fa08ef4a831f4e2281303100 (from https://pypi.org/simple/dotenv/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "  Downloading dotenv-0.0.1.tar.gz (6.5 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/fa/5a/6dcdddeaa0ddc0bd331fdd1bc8696d9650ede0cb014083716976174eb4b8/dotenv-0.0.1.tar.gz#sha256=04006132a48e301a40b5bc3e8ea0d667a68981f277bb1785af0f8b9f7958e278 (from https://pypi.org/simple/dotenv/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement dotenv (from versions: 0.0.1, 0.0.2, 0.0.4, 0.0.5)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for dotenv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e8c01dc",
        "outputId": "8ffdf281-06b2-487c-8d0e-c645efaac01a"
      },
      "source": [
        "# Load EDA Pkgs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Load ML Pkgs\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('rslp')\n",
        "from textblob import TextBlob\n",
        "\n",
        "#charts & others stuff\n",
        "from unidecode import unidecode\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import string\n",
        "from fractions import Fraction\n",
        "import json\n",
        "import os\n",
        "from googletrans import Translator\n",
        "translator = Translator()\n",
        "\n",
        "\n",
        "# from dotenv import load_dotenv\n",
        "# load_dotenv()\n",
        "# load_dotenv('../ibm-credentials.env')\n",
        "\n",
        "# IBM Watson\n",
        "from ibm_watson import NaturalLanguageUnderstandingV1\n",
        "from ibm_watson import LanguageTranslatorV3\n",
        "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
        "from ibm_watson.natural_language_understanding_v1  import Features, CategoriesOptions, SentimentOptions\n",
        "\n",
        "\n",
        "\n",
        "# NATURAL_LANGUAGE_UNDERSTANDING_APIKEY = os.environ['NATURAL_LANGUAGE_UNDERSTANDING_APIKEY']\n",
        "# NATURAL_LANGUAGE_UNDERSTANDING_URL    = os.environ['NATURAL_LANGUAGE_UNDERSTANDING_URL']\n",
        "\n",
        "# LANGUAGE_TRANSLATOR_APIKEY = os.environ['LANGUAGE_TRANSLATOR_APIKEY']\n",
        "# LANGUAGE_TRANSLATOR_URL    = os.environ['LANGUAGE_TRANSLATOR_URL']"
      ],
      "id": "2e8c01dc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtAcHtNnFtSJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "2c4230e6-3543-4728-ea12-61332e19172c"
      },
      "source": [
        "authenticator = IAMAuthenticator(f'{NATURAL_LANGUAGE_UNDERSTANDING_APIKEY}')\n",
        "natural_language_understanding = NaturalLanguageUnderstandingV1(\n",
        "    version='2021-08-01',\n",
        "    authenticator=authenticator\n",
        ")\n",
        "\n",
        "natural_language_understanding.set_service_url(f'{NATURAL_LANGUAGE_UNDERSTANDING_URL}')"
      ],
      "id": "GtAcHtNnFtSJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6b30164e8333>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mauthenticator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIAMAuthenticator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{NATURAL_LANGUAGE_UNDERSTANDING_APIKEY}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m natural_language_understanding = NaturalLanguageUnderstandingV1(\n\u001b[1;32m      3\u001b[0m     \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2021-08-01'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mauthenticator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauthenticator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'NATURAL_LANGUAGE_UNDERSTANDING_APIKEY' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zszkLINoFtSK"
      },
      "source": [
        "## Carrega os Tweets"
      ],
      "id": "zszkLINoFtSK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVwtol7iFtSL"
      },
      "source": [
        "# #Carrega todos os arquivos\n",
        "# df_o = pd.DataFrame()\n",
        "# for filename in os.listdir('../data/'):    \n",
        "#     df_o = df_o.append(pd.read_json(f\"../data/{filename}\", lines=True))\n",
        "\n",
        "# #remove tweets que eventualmente estao duplicados \n",
        "# df_o.drop_duplicates(subset=['id_str', 'search_term'], inplace=True)\n",
        "\n",
        "# #Recria o indice, pq carregou por pedacos\n",
        "# df_o.reset_index(drop=True, inplace=True)\n",
        "# df_o.shape"
      ],
      "id": "FVwtol7iFtSL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8eIUIPfFtSM"
      },
      "source": [
        "### Restaura BAckup caso necessario (evitar gastar a conta da IBM Cloud)"
      ],
      "id": "f8eIUIPfFtSM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2A8Y9R6FtSN"
      },
      "source": [
        "# df = pd.read_csv(f\"tweets_com_ibm_watson_old.csv\")\n",
        "df_o = pd.read_csv(f\"tweets_com_ibm_watson_e_ingles.csv\")\n",
        "\n",
        "# df.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n"
      ],
      "id": "G2A8Y9R6FtSN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlSlFBHAFtSO"
      },
      "source": [
        "### FAz uma proxy, just because"
      ],
      "id": "zlSlFBHAFtSO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVpP7-lbFtSQ",
        "outputId": "ac33f526-4235-41f2-b696-d4e9bbfe2e52"
      },
      "source": [
        "#df = df_o[['id_str', 'text', 'screen_name', 'search_term', 'search_term_group', 'source']]\n",
        "df = df_o# .sample(20)\n",
        "df.shape"
      ],
      "id": "cVpP7-lbFtSQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9673, 24)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je10hLCcFtSR"
      },
      "source": [
        "# Marca o sentimento a partir do IBM Watson"
      ],
      "id": "Je10hLCcFtSR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf_DQ0MeFtSR"
      },
      "source": [
        "## Teste do IBM Watson"
      ],
      "id": "kf_DQ0MeFtSR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb59eUyIFtSS"
      },
      "source": [
        "#response = natural_language_understanding.analyze(language='pt', text='inclusive muito feliz que entrou pro catálogo da amazon prime', features=Features(sentiment=SentimentOptions())).get_result()\n",
        "# print(json.dumps(response, indent=2))\n",
        "''' \n",
        "{\n",
        "  \"usage\": {\n",
        "    \"text_units\": 1,\n",
        "    \"text_characters\": 61,\n",
        "    \"features\": 1\n",
        "  },\n",
        "  \"sentiment\": {\n",
        "    \"document\": {\n",
        "      \"score\": 0.862283,\n",
        "      \"label\": \"positive\"\n",
        "    }\n",
        "  },\n",
        "  \"language\": \"pt\"\n",
        "}\n",
        "'''\n",
        "# response = natural_language_understanding.analyze(language='pt', text='Que coisa chata essa transmissão do #Bellator268 no Star+. Torcida gratuita com narrador e comentarista acabando co… https://t.co/2y7Y0cJO0e', features=Features(sentiment=SentimentOptions())).get_result()\n",
        "# print(json.dumps(response, indent=2))\n",
        "''' \n",
        "{\n",
        "  \"usage\": {\n",
        "    \"text_units\": 1,\n",
        "    \"text_characters\": 140,\n",
        "    \"features\": 1\n",
        "  },\n",
        "  \"sentiment\": {\n",
        "    \"document\": {\n",
        "      \"score\": -0.748979,\n",
        "      \"label\": \"negative\"\n",
        "    }\n",
        "  },\n",
        "  \"language\": \"pt\"\n",
        "}\n",
        "'''\n"
      ],
      "id": "Cb59eUyIFtSS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hN-0jeNFtST"
      },
      "source": [
        "## Marca a base de dados com o IBM Watson"
      ],
      "id": "5hN-0jeNFtST"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3bfa11b"
      },
      "source": [
        "# Conecta nos servidores do Watson e realiza a analise de sentimento\n",
        "# guarda o resultado em uma coluna\n",
        "def WatsonSentiment(Tweet):\n",
        "    response = natural_language_understanding.analyze(language='pt', text=Tweet, features=Features(sentiment=SentimentOptions())).get_result()\n",
        "    #print(f\"{response['sentiment']['document']['score']} : {Tweet}\")\n",
        "    return response['sentiment']['document']['score'], response['sentiment']['document']['label']\n",
        "\n",
        "# Cria as novas colunas do DataFrame\n",
        "df['ibm_watson_sentiment'], df['ibm_watson_sentiment_label'] = zip(*df['text'].map(WatsonSentiment))"
      ],
      "id": "c3bfa11b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBTBjdPCFtSU"
      },
      "source": [
        "#df[['id_str', 'text', 'screen_name', 'search_term', 'search_term_group', 'source', 'ibm_watson_sentiment', 'ibm_watson_sentiment_label']].sample(10)\n",
        "df[['id_str', 'text', 'screen_name', 'search_term', 'search_term_group', 'source']].loc[df['search_term_group'].ne('star+')].sample(15)"
      ],
      "id": "BBTBjdPCFtSU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcH8aw7TFtSW"
      },
      "source": [
        "## Salva para nao perder"
      ],
      "id": "gcH8aw7TFtSW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwdGWmGZFtSX"
      },
      "source": [
        "filename = \"tweets_com_ibm_watson\"\n",
        "df.to_csv(f\"{filename}.csv\")\n",
        "df.to_json(f\"{filename}.json\", orient='values')\n",
        "df.to_excel(f\"{filename}.xlsx\")"
      ],
      "id": "ZwdGWmGZFtSX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2KIPc40FtSX"
      },
      "source": [
        "df.sample(20)"
      ],
      "id": "O2KIPc40FtSX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj0GFwSdFtSY"
      },
      "source": [
        "# Prepara a base para rodar com a versão em ingles do TextBlob"
      ],
      "id": "oj0GFwSdFtSY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C61zzg34FtSZ"
      },
      "source": [
        "## Teste do Google Translator"
      ],
      "id": "C61zzg34FtSZ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0pkB2eqFtSZ"
      },
      "source": [
        "response = translator.translate('inclusive muito feliz que entrou pro catálogo da amazon prime', src=\"PT\", dest='EN').text\n",
        "print(json.dumps(response, indent=2))"
      ],
      "id": "h0pkB2eqFtSZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlp5SsCOFtSa"
      },
      "source": [
        "## Testa o IBM Watson Translator"
      ],
      "id": "qlp5SsCOFtSa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB2dSjTYFtSa"
      },
      "source": [
        "# Autenticação com a chave gerada na IBM CLoud\n",
        "authenticator = IAMAuthenticator(f'{LANGUAGE_TRANSLATOR_APIKEY}')\n",
        "\n",
        "#Inicia a componente com a URL provida na IBM Cloud\n",
        "language_translator = LanguageTranslatorV3(\n",
        "    version='2018-05-01',\n",
        "    authenticator=authenticator\n",
        ")\n",
        "language_translator.set_service_url(f'{LANGUAGE_TRANSLATOR_URL}')\n",
        "\n",
        "#Testa uma tradução (cuidado com a quantidade de eventos gratuitos)\n",
        "# translation = language_translator.translate(\n",
        "#     text='Hello, how are you today?',\n",
        "#     model_id='en-pt').get_result()\n",
        "\n",
        "# Imprime o resultado\n",
        "# print(json.dumps(translation, indent=2, ensure_ascii=False))\n",
        "''' \n",
        "{\n",
        "  \"translations\": [\n",
        "    {\n",
        "      \"translation\": \"Olá, como você está hoje?\"\n",
        "    }\n",
        "  ],\n",
        "  \"word_count\": 7,\n",
        "  \"character_count\": 25\n",
        "}\n",
        "'''"
      ],
      "id": "NB2dSjTYFtSa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJd8GVoAFtSb"
      },
      "source": [
        "## Marca a versao Inglesa via TextBlob"
      ],
      "id": "fJd8GVoAFtSb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XrsimtPFtSb"
      },
      "source": [
        "### Conta os caracteres para avaliar junto ao servico gratuito se cabe"
      ],
      "id": "6XrsimtPFtSb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhC-F8p4FtSc"
      },
      "source": [
        "len(\"\".join(df['text']))\n",
        "\n",
        "\n",
        "dft = df.sample(3)\n",
        "dft"
      ],
      "id": "MhC-F8p4FtSc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as42Nio5FtSc"
      },
      "source": [
        "### Primeiro, traduz o texto"
      ],
      "id": "as42Nio5FtSc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0QSZdxUFtSc"
      },
      "source": [
        "# Traduzindo para o Inglês\n",
        "# Conecta nos servidores do Watson e realiza a analise de sentimento\n",
        "# guarda o resultado em uma coluna\n",
        "def WatsonTranslate(Tweet):\n",
        "    response = language_translator.translate(text=Tweet,  model_id='pt-en').get_result()\n",
        "    translations = response['translations']    \n",
        "    #print(f\"{translations[0]['translation']} : {Tweet} :: {response['character_count']}\")\n",
        "    return translations[0]['translation'], response['character_count']\n",
        "\n",
        "\n",
        "df['textEN'], df['ibm_watson_tranlation_character_count'] = zip(*df['text'].map(WatsonTranslate))\n",
        "#dft['textEN'], dft['ibm_watson_tranlation_character_count'] = zip(*dft['text'].map(WatsonTranslate))\n",
        "\n",
        "# Versão Google (Rate Limit applied)\n",
        "#df['textEN'] = df['text'].apply(lambda x: translator.translate(x, src=\"PT\", dest='EN').text)"
      ],
      "id": "x0QSZdxUFtSc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6E7320CFtSd"
      },
      "source": [
        "df"
      ],
      "id": "c6E7320CFtSd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zpFtedfFtSd"
      },
      "source": [
        "### Marca sentimento pelo TextBlob"
      ],
      "id": "-zpFtedfFtSd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlGvo_HlFtSe"
      },
      "source": [
        "#Calculando o sentimento...\n",
        "df['textblob_polarity']     = df['textEN'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "df['textblob_subjectivity'] = df['textEN'].apply(lambda x: TextBlob(x).sentiment.subjectivity)"
      ],
      "id": "IlGvo_HlFtSe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX1bpbqeFtSe"
      },
      "source": [
        "## Salva para nao perder"
      ],
      "id": "UX1bpbqeFtSe"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mNo6sdYFtSe"
      },
      "source": [
        "filename = \"tweets_com_ibm_watson_e_ingles\"\n",
        "df.to_csv(f\"{filename}.csv\")\n",
        "df.to_json(f\"{filename}.json\", orient='values')\n",
        "df.to_excel(f\"{filename}.xlsx\")"
      ],
      "id": "5mNo6sdYFtSe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH9COib0Gz_w"
      },
      "source": [
        "# Naive Bayes"
      ],
      "id": "YH9COib0Gz_w"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ri6S58wG-st",
        "outputId": "209897bc-8699-4785-a411-b451e8c5bb2a"
      },
      "source": [
        "df_nb = df.sample(10)\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "#Arnaldo Jabor\n",
        "X = vectorizer.fit_transform(df_nb['text'])\n",
        "Y = df_nb['ibm_watson_sentiment_label']\n",
        "vocabulary = vectorizer.get_feature_names()\n",
        "dfX = pd.DataFrame(data=X.toarray(), columns=vocabulary) #.iloc[:,0::2]\n",
        "Y"
      ],
      "id": "2Ri6S58wG-st",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7875     neutral\n",
              "9482    positive\n",
              "933     negative\n",
              "2031    negative\n",
              "3960    negative\n",
              "1487    negative\n",
              "1371    positive\n",
              "7795    negative\n",
              "3671    positive\n",
              "7438     neutral\n",
              "Name: ibm_watson_sentiment_label, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "PJz5bdwpKjqC",
        "outputId": "30f8e76d-047b-410b-d548-649bfb96233b"
      },
      "source": [
        "df.describe()"
      ],
      "id": "PJz5bdwpKjqC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Unnamed: 0  favorite_count  followers_count            id  \\\n",
              "count  9673.000000     9673.000000     9.673000e+03  9.673000e+03   \n",
              "mean   4836.000000       11.359971     5.691394e+04  4.832581e+17   \n",
              "std    2792.498911      167.273884     4.698256e+05  5.701233e+17   \n",
              "min       0.000000        0.000000     0.000000e+00  7.927950e+05   \n",
              "25%    2418.000000        0.000000     1.290000e+02  1.064530e+08   \n",
              "50%    4836.000000        1.000000     4.350000e+02  2.948113e+09   \n",
              "75%    7254.000000        2.000000     2.026000e+03  1.077593e+18   \n",
              "max    9672.000000    13936.000000     1.696435e+07  1.452034e+18   \n",
              "\n",
              "             id_str  retweet_count  ibm_watson_sentiment  \\\n",
              "count  9.673000e+03    9673.000000           9673.000000   \n",
              "mean   1.450957e+18       0.893725              0.031843   \n",
              "std    8.789754e+14      17.747758              0.666091   \n",
              "min    1.449260e+18       0.000000             -0.997954   \n",
              "25%    1.450251e+18       0.000000             -0.640356   \n",
              "50%    1.450976e+18       0.000000              0.000000   \n",
              "75%    1.451619e+18       0.000000              0.691498   \n",
              "max    1.452619e+18    1227.000000              0.999999   \n",
              "\n",
              "       ibm_watson_tranlation_character_count  textblob_polarity  \\\n",
              "count                            9673.000000        9673.000000   \n",
              "mean                              101.745270           0.080189   \n",
              "std                                35.971436           0.294877   \n",
              "min                                12.000000          -1.000000   \n",
              "25%                                70.000000           0.000000   \n",
              "50%                               106.000000           0.000000   \n",
              "75%                               140.000000           0.200000   \n",
              "max                               180.000000           1.000000   \n",
              "\n",
              "       textblob_subjectivity  \n",
              "count            9673.000000  \n",
              "mean                0.335639  \n",
              "std                 0.325208  \n",
              "min                 0.000000  \n",
              "25%                 0.000000  \n",
              "50%                 0.316667  \n",
              "75%                 0.600000  \n",
              "max                 1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-770828f9-6639-4e85-b200-9a864326dcc1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>followers_count</th>\n",
              "      <th>id</th>\n",
              "      <th>id_str</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>ibm_watson_sentiment</th>\n",
              "      <th>ibm_watson_tranlation_character_count</th>\n",
              "      <th>textblob_polarity</th>\n",
              "      <th>textblob_subjectivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>9673.000000</td>\n",
              "      <td>9673.000000</td>\n",
              "      <td>9.673000e+03</td>\n",
              "      <td>9.673000e+03</td>\n",
              "      <td>9.673000e+03</td>\n",
              "      <td>9673.000000</td>\n",
              "      <td>9673.000000</td>\n",
              "      <td>9673.000000</td>\n",
              "      <td>9673.000000</td>\n",
              "      <td>9673.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4836.000000</td>\n",
              "      <td>11.359971</td>\n",
              "      <td>5.691394e+04</td>\n",
              "      <td>4.832581e+17</td>\n",
              "      <td>1.450957e+18</td>\n",
              "      <td>0.893725</td>\n",
              "      <td>0.031843</td>\n",
              "      <td>101.745270</td>\n",
              "      <td>0.080189</td>\n",
              "      <td>0.335639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2792.498911</td>\n",
              "      <td>167.273884</td>\n",
              "      <td>4.698256e+05</td>\n",
              "      <td>5.701233e+17</td>\n",
              "      <td>8.789754e+14</td>\n",
              "      <td>17.747758</td>\n",
              "      <td>0.666091</td>\n",
              "      <td>35.971436</td>\n",
              "      <td>0.294877</td>\n",
              "      <td>0.325208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>7.927950e+05</td>\n",
              "      <td>1.449260e+18</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.997954</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2418.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.290000e+02</td>\n",
              "      <td>1.064530e+08</td>\n",
              "      <td>1.450251e+18</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.640356</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4836.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.350000e+02</td>\n",
              "      <td>2.948113e+09</td>\n",
              "      <td>1.450976e+18</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.316667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7254.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.026000e+03</td>\n",
              "      <td>1.077593e+18</td>\n",
              "      <td>1.451619e+18</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.691498</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9672.000000</td>\n",
              "      <td>13936.000000</td>\n",
              "      <td>1.696435e+07</td>\n",
              "      <td>1.452034e+18</td>\n",
              "      <td>1.452619e+18</td>\n",
              "      <td>1227.000000</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>180.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-770828f9-6639-4e85-b200-9a864326dcc1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-770828f9-6639-4e85-b200-9a864326dcc1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-770828f9-6639-4e85-b200-9a864326dcc1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}